Loading data...1681 evaluation sequencesBERT_CRFallenai/scibert_scivocab_cased/dir will be used, loaded via delft_modelload weights from data/models/sequenceLabelling/grobid-units_1-BERT_CRF/model_weights.hdf5loading model weights data/models/sequenceLabelling/grobid-units_1-BERT_CRF/model_weights.hdf5Model: "model"__________________________________________________________________________________________________ Layer (type)                   Output Shape         Param #     Connected to                     ================================================================================================== input_token (InputLayer)       [(None, None)]       0           []                                                                                                                                  input_attention_mask (InputLay  [(None, None)]      0           []                                er)                                                                                                                                                                                                 input_token_type (InputLayer)  [(None, None)]       0           []                                                                                                                                  tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109938432   ['input_token[0][0]',                                            thPoolingAndCrossAt               'input_attention_mask[0][0]',                                   tentions(last_hidde               'input_token_type[0][0]']                                       n_state=(None, None                                                                               , 768),                                                                                            pooler_output=(Non                                                                               e, 768),                                                                                           past_key_values=No                                                                               ne, hidden_states=N                                                                               one, attentions=Non                                                                               e, cross_attentions                                                                               =None)                                                                                                                                                               dropout_37 (Dropout)           (None, None, 768)    0           ['tf_bert_model[0][0]']                                                                                                            ==================================================================================================Total params: 109,938,432Trainable params: 109,938,432Non-trainable params: 0__________________________________________________________________________________________________Model: "crf_model_wrapper_for_bert"_________________________________________________________________ Layer (type)                Output Shape              Param #   ================================================================= crf (CRF)                   multiple                  5446                                                                        model (Functional)          (None, None, 768)         109938432                                                                  =================================================================Total params: 109,943,878Trainable params: 109,943,878Non-trainable params: 0_________________________________________________________________Evaluation:---max_epoch: 50early_stop: Truepatience: 5batch_size (training): 20max_sequence_length: 100model_name: grobid-units_1-BERT_CRFlearning_rate:  0.001use_ELMo:  False---Model: "model"__________________________________________________________________________________________________ Layer (type)                   Output Shape         Param #     Connected to                     ================================================================================================== input_token (InputLayer)       [(None, None)]       0           []                                                                                                                                  input_attention_mask (InputLay  [(None, None)]      0           []                                er)                                                                                                                                                                                                 input_token_type (InputLayer)  [(None, None)]       0           []                                                                                                                                  tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109938432   ['input_token[0][0]',                                            thPoolingAndCrossAt               'input_attention_mask[0][0]',                                   tentions(last_hidde               'input_token_type[0][0]']                                       n_state=(None, None                                                                               , 768),                                                                                            pooler_output=(Non                                                                               e, 768),                                                                                           past_key_values=No                                                                               ne, hidden_states=N                                                                               one, attentions=Non                                                                               e, cross_attentions                                                                               =None)                                                                                                                                                               dropout_37 (Dropout)           (None, None, 768)    0           ['tf_bert_model[0][0]']                                                                                                            ==================================================================================================Total params: 109,938,432Trainable params: 109,938,432Non-trainable params: 0__________________________________________________________________________________________________Model: "crf_model_wrapper_for_bert"_________________________________________________________________ Layer (type)                Output Shape              Param #   ================================================================= crf (CRF)                   multiple                  5446                                                                        model (Functional)          (None, None, 768)         109938432                                                                  =================================================================Total params: 109,943,878Trainable params: 109,943,878Non-trainable params: 0_________________________________________________________________                  precision    recall  f1-score   support          <base>     0.7834    0.7732    0.7783      3228           <pow>     0.7229    0.5296    0.6113      1773        <prefix>     0.7572    0.9037    0.8239      1287all (micro avg.)     0.7637    0.7312    0.7471      6288Evaluation runtime: 21.14 seconds Loading data...1681 evaluation sequencesBERT_CRFallenai/scibert_scivocab_cased/dir will be used, loaded via delft_modelload weights from data/models/sequenceLabelling/grobid-units_2-BERT_CRF/model_weights.hdf5loading model weights data/models/sequenceLabelling/grobid-units_2-BERT_CRF/model_weights.hdf5Model: "model"__________________________________________________________________________________________________ Layer (type)                   Output Shape         Param #     Connected to                     ================================================================================================== input_token (InputLayer)       [(None, None)]       0           []                                                                                                                                  input_attention_mask (InputLay  [(None, None)]      0           []                                er)                                                                                                                                                                                                 input_token_type (InputLayer)  [(None, None)]       0           []                                                                                                                                  tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109938432   ['input_token[0][0]',                                            thPoolingAndCrossAt               'input_attention_mask[0][0]',                                   tentions(last_hidde               'input_token_type[0][0]']                                       n_state=(None, None                                                                               , 768),                                                                                            pooler_output=(Non                                                                               e, 768),                                                                                           past_key_values=No                                                                               ne, hidden_states=N                                                                               one, attentions=Non                                                                               e, cross_attentions                                                                               =None)                                                                                                                                                               dropout_37 (Dropout)           (None, None, 768)    0           ['tf_bert_model[0][0]']                                                                                                            ==================================================================================================Total params: 109,938,432Trainable params: 109,938,432Non-trainable params: 0__________________________________________________________________________________________________Model: "crf_model_wrapper_for_bert"_________________________________________________________________ Layer (type)                Output Shape              Param #   ================================================================= crf (CRF)                   multiple                  5446                                                                        model (Functional)          (None, None, 768)         109938432                                                                  =================================================================Total params: 109,943,878Trainable params: 109,943,878Non-trainable params: 0_________________________________________________________________Evaluation:---max_epoch: 50early_stop: Truepatience: 5batch_size (training): 20max_sequence_length: 100model_name: grobid-units_2-BERT_CRFlearning_rate:  0.001use_ELMo:  False---Model: "model"__________________________________________________________________________________________________ Layer (type)                   Output Shape         Param #     Connected to                     ================================================================================================== input_token (InputLayer)       [(None, None)]       0           []                                                                                                                                  input_attention_mask (InputLay  [(None, None)]      0           []                                er)                                                                                                                                                                                                 input_token_type (InputLayer)  [(None, None)]       0           []                                                                                                                                  tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109938432   ['input_token[0][0]',                                            thPoolingAndCrossAt               'input_attention_mask[0][0]',                                   tentions(last_hidde               'input_token_type[0][0]']                                       n_state=(None, None                                                                               , 768),                                                                                            pooler_output=(Non                                                                               e, 768),                                                                                           past_key_values=No                                                                               ne, hidden_states=N                                                                               one, attentions=Non                                                                               e, cross_attentions                                                                               =None)                                                                                                                                                               dropout_37 (Dropout)           (None, None, 768)    0           ['tf_bert_model[0][0]']                                                                                                            ==================================================================================================Total params: 109,938,432Trainable params: 109,938,432Non-trainable params: 0__________________________________________________________________________________________________Model: "crf_model_wrapper_for_bert"_________________________________________________________________ Layer (type)                Output Shape              Param #   ================================================================= crf (CRF)                   multiple                  5446                                                                        model (Functional)          (None, None, 768)         109938432                                                                  =================================================================Total params: 109,943,878Trainable params: 109,943,878Non-trainable params: 0_________________________________________________________________                  precision    recall  f1-score   support          <base>     0.7201    0.7875    0.7523      3228           <pow>     0.9488    0.5849    0.7237      1773        <prefix>     0.6990    0.9005    0.7871      1287all (micro avg.)     0.7543    0.7535    0.7539      6288Evaluation runtime: 21.382 seconds Loading data...1681 evaluation sequencesBERT_CRFallenai/scibert_scivocab_cased/dir will be used, loaded via delft_modelload weights from data/models/sequenceLabelling/grobid-units_3-BERT_CRF/model_weights.hdf5loading model weights data/models/sequenceLabelling/grobid-units_3-BERT_CRF/model_weights.hdf5Model: "model"__________________________________________________________________________________________________ Layer (type)                   Output Shape         Param #     Connected to                     ================================================================================================== input_token (InputLayer)       [(None, None)]       0           []                                                                                                                                  input_attention_mask (InputLay  [(None, None)]      0           []                                er)                                                                                                                                                                                                 input_token_type (InputLayer)  [(None, None)]       0           []                                                                                                                                  tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109938432   ['input_token[0][0]',                                            thPoolingAndCrossAt               'input_attention_mask[0][0]',                                   tentions(last_hidde               'input_token_type[0][0]']                                       n_state=(None, None                                                                               , 768),                                                                                            pooler_output=(Non                                                                               e, 768),                                                                                           past_key_values=No                                                                               ne, hidden_states=N                                                                               one, attentions=Non                                                                               e, cross_attentions                                                                               =None)                                                                                                                                                               dropout_37 (Dropout)           (None, None, 768)    0           ['tf_bert_model[0][0]']                                                                                                            ==================================================================================================Total params: 109,938,432Trainable params: 109,938,432Non-trainable params: 0__________________________________________________________________________________________________Model: "crf_model_wrapper_for_bert"_________________________________________________________________ Layer (type)                Output Shape              Param #   ================================================================= crf (CRF)                   multiple                  5446                                                                        model (Functional)          (None, None, 768)         109938432                                                                  =================================================================Total params: 109,943,878Trainable params: 109,943,878Non-trainable params: 0_________________________________________________________________Evaluation:---max_epoch: 50early_stop: Truepatience: 5batch_size (training): 20max_sequence_length: 100model_name: grobid-units_3-BERT_CRFlearning_rate:  0.001use_ELMo:  False---Model: "model"__________________________________________________________________________________________________ Layer (type)                   Output Shape         Param #     Connected to                     ================================================================================================== input_token (InputLayer)       [(None, None)]       0           []                                                                                                                                  input_attention_mask (InputLay  [(None, None)]      0           []                                er)                                                                                                                                                                                                 input_token_type (InputLayer)  [(None, None)]       0           []                                                                                                                                  tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109938432   ['input_token[0][0]',                                            thPoolingAndCrossAt               'input_attention_mask[0][0]',                                   tentions(last_hidde               'input_token_type[0][0]']                                       n_state=(None, None                                                                               , 768),                                                                                            pooler_output=(Non                                                                               e, 768),                                                                                           past_key_values=No                                                                               ne, hidden_states=N                                                                               one, attentions=Non                                                                               e, cross_attentions                                                                               =None)                                                                                                                                                               dropout_37 (Dropout)           (None, None, 768)    0           ['tf_bert_model[0][0]']                                                                                                            ==================================================================================================Total params: 109,938,432Trainable params: 109,938,432Non-trainable params: 0__________________________________________________________________________________________________Model: "crf_model_wrapper_for_bert"_________________________________________________________________ Layer (type)                Output Shape              Param #   ================================================================= crf (CRF)                   multiple                  5446                                                                        model (Functional)          (None, None, 768)         109938432                                                                  =================================================================Total params: 109,943,878Trainable params: 109,943,878Non-trainable params: 0_________________________________________________________________                  precision    recall  f1-score   support          <base>     0.8405    0.7556    0.7958      3228           <pow>     0.6210    0.4095    0.4935      1773        <prefix>     0.6078    0.9596    0.7442      1287all (micro avg.)     0.7210    0.6997    0.7102      6288Evaluation runtime: 21.508 seconds Loading data...1681 evaluation sequencesBERT_CRFallenai/scibert_scivocab_cased/dir will be used, loaded via delft_modelload weights from data/models/sequenceLabelling/grobid-units_4-BERT_CRF/model_weights.hdf5loading model weights data/models/sequenceLabelling/grobid-units_4-BERT_CRF/model_weights.hdf5Model: "model"__________________________________________________________________________________________________ Layer (type)                   Output Shape         Param #     Connected to                     ================================================================================================== input_token (InputLayer)       [(None, None)]       0           []                                                                                                                                  input_attention_mask (InputLay  [(None, None)]      0           []                                er)                                                                                                                                                                                                 input_token_type (InputLayer)  [(None, None)]       0           []                                                                                                                                  tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109938432   ['input_token[0][0]',                                            thPoolingAndCrossAt               'input_attention_mask[0][0]',                                   tentions(last_hidde               'input_token_type[0][0]']                                       n_state=(None, None                                                                               , 768),                                                                                            pooler_output=(Non                                                                               e, 768),                                                                                           past_key_values=No                                                                               ne, hidden_states=N                                                                               one, attentions=Non                                                                               e, cross_attentions                                                                               =None)                                                                                                                                                               dropout_37 (Dropout)           (None, None, 768)    0           ['tf_bert_model[0][0]']                                                                                                            ==================================================================================================Total params: 109,938,432Trainable params: 109,938,432Non-trainable params: 0__________________________________________________________________________________________________Model: "crf_model_wrapper_for_bert"_________________________________________________________________ Layer (type)                Output Shape              Param #   ================================================================= crf (CRF)                   multiple                  5446                                                                        model (Functional)          (None, None, 768)         109938432                                                                  =================================================================Total params: 109,943,878Trainable params: 109,943,878Non-trainable params: 0_________________________________________________________________Evaluation:---max_epoch: 50early_stop: Truepatience: 5batch_size (training): 20max_sequence_length: 100model_name: grobid-units_4-BERT_CRFlearning_rate:  0.001use_ELMo:  False---Model: "model"__________________________________________________________________________________________________ Layer (type)                   Output Shape         Param #     Connected to                     ================================================================================================== input_token (InputLayer)       [(None, None)]       0           []                                                                                                                                  input_attention_mask (InputLay  [(None, None)]      0           []                                er)                                                                                                                                                                                                 input_token_type (InputLayer)  [(None, None)]       0           []                                                                                                                                  tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109938432   ['input_token[0][0]',                                            thPoolingAndCrossAt               'input_attention_mask[0][0]',                                   tentions(last_hidde               'input_token_type[0][0]']                                       n_state=(None, None                                                                               , 768),                                                                                            pooler_output=(Non                                                                               e, 768),                                                                                           past_key_values=No                                                                               ne, hidden_states=N                                                                               one, attentions=Non                                                                               e, cross_attentions                                                                               =None)                                                                                                                                                               dropout_37 (Dropout)           (None, None, 768)    0           ['tf_bert_model[0][0]']                                                                                                            ==================================================================================================Total params: 109,938,432Trainable params: 109,938,432Non-trainable params: 0__________________________________________________________________________________________________Model: "crf_model_wrapper_for_bert"_________________________________________________________________ Layer (type)                Output Shape              Param #   ================================================================= crf (CRF)                   multiple                  5446                                                                        model (Functional)          (None, None, 768)         109938432                                                                  =================================================================Total params: 109,943,878Trainable params: 109,943,878Non-trainable params: 0_________________________________________________________________                  precision    recall  f1-score   support          <base>     0.6928    0.7559    0.7230      3228           <pow>     0.9112    0.6080    0.7294      1773        <prefix>     0.6697    0.9091    0.7713      1287all (micro avg.)     0.7266    0.7455    0.7359      6288Evaluation runtime: 20.972 seconds Loading data...1681 evaluation sequencesBERT_CRFallenai/scibert_scivocab_cased/dir will be used, loaded via delft_modelload weights from data/models/sequenceLabelling/grobid-units_5-BERT_CRF/model_weights.hdf5loading model weights data/models/sequenceLabelling/grobid-units_5-BERT_CRF/model_weights.hdf5Model: "model"__________________________________________________________________________________________________ Layer (type)                   Output Shape         Param #     Connected to                     ================================================================================================== input_token (InputLayer)       [(None, None)]       0           []                                                                                                                                  input_attention_mask (InputLay  [(None, None)]      0           []                                er)                                                                                                                                                                                                 input_token_type (InputLayer)  [(None, None)]       0           []                                                                                                                                  tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109938432   ['input_token[0][0]',                                            thPoolingAndCrossAt               'input_attention_mask[0][0]',                                   tentions(last_hidde               'input_token_type[0][0]']                                       n_state=(None, None                                                                               , 768),                                                                                            pooler_output=(Non                                                                               e, 768),                                                                                           past_key_values=No                                                                               ne, hidden_states=N                                                                               one, attentions=Non                                                                               e, cross_attentions                                                                               =None)                                                                                                                                                               dropout_37 (Dropout)           (None, None, 768)    0           ['tf_bert_model[0][0]']                                                                                                            ==================================================================================================Total params: 109,938,432Trainable params: 109,938,432Non-trainable params: 0__________________________________________________________________________________________________Model: "crf_model_wrapper_for_bert"_________________________________________________________________ Layer (type)                Output Shape              Param #   ================================================================= crf (CRF)                   multiple                  5446                                                                        model (Functional)          (None, None, 768)         109938432                                                                  =================================================================Total params: 109,943,878Trainable params: 109,943,878Non-trainable params: 0_________________________________________________________________Evaluation:---max_epoch: 50early_stop: Truepatience: 5batch_size (training): 20max_sequence_length: 100model_name: grobid-units_5-BERT_CRFlearning_rate:  0.001use_ELMo:  False---Model: "model"__________________________________________________________________________________________________ Layer (type)                   Output Shape         Param #     Connected to                     ================================================================================================== input_token (InputLayer)       [(None, None)]       0           []                                                                                                                                  input_attention_mask (InputLay  [(None, None)]      0           []                                er)                                                                                                                                                                                                 input_token_type (InputLayer)  [(None, None)]       0           []                                                                                                                                  tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109938432   ['input_token[0][0]',                                            thPoolingAndCrossAt               'input_attention_mask[0][0]',                                   tentions(last_hidde               'input_token_type[0][0]']                                       n_state=(None, None                                                                               , 768),                                                                                            pooler_output=(Non                                                                               e, 768),                                                                                           past_key_values=No                                                                               ne, hidden_states=N                                                                               one, attentions=Non                                                                               e, cross_attentions                                                                               =None)                                                                                                                                                               dropout_37 (Dropout)           (None, None, 768)    0           ['tf_bert_model[0][0]']                                                                                                            ==================================================================================================Total params: 109,938,432Trainable params: 109,938,432Non-trainable params: 0__________________________________________________________________________________________________Model: "crf_model_wrapper_for_bert"_________________________________________________________________ Layer (type)                Output Shape              Param #   ================================================================= crf (CRF)                   multiple                  5446                                                                        model (Functional)          (None, None, 768)         109938432                                                                  =================================================================Total params: 109,943,878Trainable params: 109,943,878Non-trainable params: 0_________________________________________________________________                  precision    recall  f1-score   support          <base>     0.7342    0.7196    0.7268      3228           <pow>     0.8703    0.6469    0.7422      1773        <prefix>     0.6445    0.9355    0.7632      1287all (micro avg.)     0.7361    0.7433    0.7397      6288Evaluation runtime: 21.231 seconds 